---  
layout: post  
title: "Lab 10"  
tags: [lab report, fieldbook]  
author: Kenneth Haley 
---

# Lab Report 10

**Prompt**

As we did for Lab #8, I encourage you to experiment with this code in a new RMD file. Copy, paste, adapt, run, revise, run again. Can you import a different genre of literature from Project Gutenberg, for instance, and analyze it in the ways we did for science fiction? See the project’s bookshelves to figure out what you would substitute in the code to do this. Can you experiment with the paramenters of the code in other places: look at a different sentiment, for instance, or change the number of topics in your topic model? Ultimately, your fieldbook should think through the potential (and potential pitfalls) of these sorts of computational text analysis. What new possibilities do methods such as sentiment analysis or topic modeling open, and what aspects of the texts they are used to study are obscured by such methods? Finally, what other patterns might you be interested in tracing across a large collection of books? For this last question, don’t worry about whether you know how to code such an analysis—instead, focus on what you would want to do if you had the requisite familiarity with programming.



**Actual Lab Report Writing**

I initially intended to download and run an analysis on Gutenberg's collection of Horror novels, but for reasons which are still unclear I was unable to retrieve the necessary files. After some trial and error, I chose to focus on their "Fantasy" list instead. The list provided me with 57 books.

```
{r}
booklist <- gutenberg_works(gutenberg_bookshelf == "Fantasy", languages = "en", only_text = TRUE)
books <- gutenberg_download(c(booklist$gutenberg_id), meta_fields = c("title","author"), strip = TRUE) %>%
   group_by(title, author) %>%
   summarise(text = paste(text, collapse = " ")) %>%
   ungroup() %>%
   select(text, title, author)

write_tsv(books, "./data/fantasy.tsv")

 write.csv(books, file = "./data/fantasy.csv")
```

I then modified the code and ran a sentiment analysis for "love," only to come up with zero results. After some tweaking, and examining the sentiments without a specific focus, I settled on "joy" instead. I then modified the code further and ran then analysis.


```
sentiments <- get_sentiments("nrc") %>% filter(sentiment == "joy")

View(sentiments)

books_words %>%
  semi_join(sentiments) %>%
  count(word, sort = TRUE)

books_words %>% 
  filter(word %in% sentiments$word) %>%
  count(title, author, sort=TRUE) %>%
  View()

joy_books <- books_words %>% 
  filter(word %in% sentiments$word) %>%
  count(title, author, sort=TRUE) %>%
  slice(1:9)
get_sentiments("nrc") %>% View

```
I then produced a plot on the list, with the code that was provided in the initial exercise. 

While this isn't exactly what this particular lab entry wanted, I felt it was important to track the creation of the modified code both for my own potential future reference, but also to show that I was capable of it, and could work my way around small errors and pitfalls. 

Admittedly, examining Gutenberg's "Fantasy" shelf for joy is not my preferred choice of subjects, but it was a start and helped me get a better handle on what's possible with this tool. In an ideal situation, I would be able to analyze either Gutenberg's "Horror" shelf, or apply it to a different corpus entirely. For example, my NuLab project has become a portfolio of different tools and methodologies applied to the works of H.P. Lovecraft, to that end I have a corpus of 100 prose stories he created. Being able to run a sentiment analysis and track the spread of sentiments across his work and across time would be incredibly useful. Just how negative would his works be according these tools? What anomalies might be detected? Is there a specific period through which certain sentiments appeared more than another? Is there a correlation between his more popular works and specific sentiments?

On its own, sentiment analysis and topic modeling are limited and reliant upon highly subjective readings and speculation. With sentiment analysis, it requires a proper understanding of what each sentiment means and represents, though an understanding of how the words and sentiments are parsed would also seem useful. 

Meanwhile, with topic modeling, the results can be so vague they might require large jumps in logic and a strong familiarity with the subject matter. Lacking that, it requires time to get familiar with it after running a topic model as an exploratory tool to identify potential areas of interest and connections. Along those same lines, the actual process of generating the topics can be hit or miss as well, as fewer topics may produced results that are so broad as to be useless, and more topics may be so specific that they fail to provide broader connections. Ultimately, topic modeling can be a rather time consuming process, and the results may be shakier than one might hope, but when it works properly it can be helpful and rewarding in identifying ideas and connections that might have been overlooked otherwise. 
